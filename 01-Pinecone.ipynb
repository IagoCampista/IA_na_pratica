{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b72fa7c",
   "metadata": {},
   "source": [
    "1Ô∏è‚É£ Setup e Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14c043a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bibliotecas importadas com sucesso!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iagocampista/anaconda3/envs/travelAgent/lib/python3.11/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "# Imports necess√°rios\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Carregar vari√°veis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21b2825b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã √çndices existentes:\n",
      "\n",
      "====================\n",
      " [] aula-ia-01\n",
      "====================\n",
      " [] assistente-viagem\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√£o das credenciais\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_ENVIRONMENT = os.getenv('PINECONE_ENVIRONMENT', 'us-east-1')\n",
    "INDEX_NAME = \"assistente-viagem\"\n",
    "\n",
    "# Inicializar cliente Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Verificar √≠ndices existentes\n",
    "print(\"üìã √çndices existentes:\")\n",
    "print()\n",
    "print(\"=\" * 20)\n",
    "\n",
    "for index in pc.list_indexes().names():\n",
    "    print(f\" [] {index}\")\n",
    "    print(\"=\" * 20)\n",
    "\n",
    "# cria √≠ndice se n√£o existir\n",
    "if INDEX_NAME not in [i.name for i in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=384,  # depende do modelo de embeddings\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "index = pc.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4ea0d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de documentos originais: 20\n",
      "N√∫mero total de chunks gerados: 20\n",
      "\n",
      "Exemplo do primeiro chunk gerado:\n",
      "page_content='A Praia de Copacabana √© ideal para caminhadas no cal√ßad√£o e visitas a quiosques. Durante o r√©veillon, recebe milh√µes de turistas.' metadata={'cidade': 'Rio de Janeiro', 'categoria': 'Atra√ß√µes', 'subtopico': 'Praia de Copacabana'}\n",
      "\n",
      "Exemplo de um chunk de Paris:\n",
      "page_content='H√° muitos carteiristas em locais tur√≠sticos e no metr√¥; mantenha bolsas e mochilas sempre pr√≥ximas. Evite carregar muito dinheiro em esp√©cie; prefira cart√µes. Para deslocamentos noturnos em √°reas afastadas, utilize t√°xis ou aplicativos de transporte.' metadata={'cidade': 'Paris', 'categoria': 'Seguran√ßa', 'subtopico': 'Precau√ß√µes Gerais'}\n"
     ]
    }
   ],
   "source": [
    "# 1. Importe a lista de dados do arquivo separado\n",
    "from base_conhecimento import DADOS_DE_CONHECIMENTO\n",
    "\n",
    "# 2. Transformar os dados em Documentos LangChain\n",
    "documentos = []\n",
    "for item in DADOS_DE_CONHECIMENTO:\n",
    "    doc = Document(\n",
    "        page_content=item[\"conteudo\"],\n",
    "        metadata={\n",
    "            \"cidade\": item[\"cidade\"],\n",
    "            \"categoria\": item[\"categoria\"],\n",
    "            \"subtopico\": item[\"subtopico\"]\n",
    "        }\n",
    "    )\n",
    "    documentos.append(doc)\n",
    "\n",
    "# 3. Usar um TextSplitter para caso o chunck pre-estabelecido tenha ficado muito longo\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks_finais = text_splitter.split_documents(documentos)\n",
    "\n",
    "# 4. Verifique o resultado\n",
    "print(f\"N√∫mero de documentos originais: {len(documentos)}\")\n",
    "print(f\"N√∫mero total de chunks gerados: {len(chunks_finais)}\")\n",
    "print(\"\\nExemplo do primeiro chunk gerado:\")\n",
    "print(chunks_finais[2])\n",
    "\n",
    "print(\"\\nExemplo de um chunk de Paris:\")\n",
    "print(chunks_finais[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f0f24",
   "metadata": {},
   "source": [
    "Uplpad para o PineCone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba8667d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o processo de upload para o Pinecone...\n",
      "Carregando o modelo de embeddings do Hugging Face...\n",
      "Modelo de embeddings carregado com sucesso.\n",
      "Conectando ao Pinecone...\n",
      "Conex√£o estabelecida. Usando o √≠ndice: assistente-viagem\n",
      "Iniciando o upload de 20 chunks. Isso pode levar alguns minutos...\n",
      "\n",
      "--- SUCESSO! ---\n",
      "Todos os chunks foram vetorizados e enviados para o seu √≠ndice no Pinecone.\n",
      "Voc√™ j√° pode verificar o 'Vector Count' no seu dashboard do Pinecone.\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando o processo de upload para o Pinecone...\")\n",
    "\n",
    "# 2. Inicializar o modelo de Embeddings do Hugging Face\n",
    "print(\"Carregando o modelo de embeddings do Hugging Face...\")\n",
    "# O modelo ser√° baixado e armazenado em cache na primeira vez que for executado\n",
    "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "model_kwargs = {'device': 'cpu'} # For√ßar o uso da CPU\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "print(\"Modelo de embeddings carregado com sucesso.\")\n",
    "\n",
    "# 3. Inicializar a conex√£o com o Pinecone\n",
    "print(\"Conectando ao Pinecone...\")\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "index_name = \"assistente-viagem\" # O nome do seu √≠ndice com a dimens√£o correta (384)\n",
    "print(f\"Conex√£o estabelecida. Usando o √≠ndice: {index_name}\")\n",
    "\n",
    "# 4. Vetorizar e Fazer o Upload dos Chunks\n",
    "# O LangChain faz todo o trabalho pesado aqui:\n",
    "# - Pega cada chunk da lista 'chunks_finais'\n",
    "# - Usa o modelo do Hugging Face para criar um embedding (vetor)\n",
    "# - Envia o vetor e os metadados para o √≠ndice do Pinecone\n",
    "print(f\"Iniciando o upload de {len(chunks_finais)} chunks. Isso pode levar alguns minutos...\")\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=chunks_finais,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name\n",
    ")\n",
    "\n",
    "print(\"\\n--- SUCESSO! ---\")\n",
    "print(\"Todos os chunks foram vetorizados e enviados para o seu √≠ndice no Pinecone.\")\n",
    "print(\"Voc√™ j√° pode verificar o 'Vector Count' no seu dashboard do Pinecone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1684984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para caso seja necessario apagar os dados do pinecone (debugging)\n",
    "#index.delete(delete_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe2a3247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç **TESTE DE BUSCA:** 'pontos tur√≠sticos famosos'\n",
      "\n",
      "üìã **RESULTADOS:**\n",
      "\n",
      "1. **RIO DE JANEIRO** (Score: 0.628)\n",
      "   A Praia de Copacabana √© ideal para caminhadas no cal√ßad√£o e visitas a quiosques. Durante o r√©veillon, recebe milh√µes de turistas.\n",
      "\n",
      "2. **PARIS** (Score: 0.532)\n",
      "   Os passeios de barco pelo Rio Sena permitem conhecer os principais monumentos de Paris de uma perspectiva diferente.\n",
      "\n",
      "3. **RIO DE JANEIRO** (Score: 0.528)\n",
      "   Durante grandes eventos como carnaval e r√©veillon, √© importante reservar hospedagem e passagens com anteced√™ncia.\n"
     ]
    }
   ],
   "source": [
    "# Teste de busca simples\n",
    "query = \"pontos tur√≠sticos famosos\"\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "# Buscar documentos similares\n",
    "results = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=3,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(f\"üîç **TESTE DE BUSCA:** '{query}'\")\n",
    "print(\"\\nüìã **RESULTADOS:**\")\n",
    "for i, match in enumerate(results['matches'], 1):\n",
    "    score = match['score']\n",
    "    text = match['metadata']['text']\n",
    "    cidade = match['metadata']['cidade']\n",
    "    \n",
    "    print(f\"\\n{i}. **{cidade.upper()}** (Score: {score:.3f})\")\n",
    "    print(f\"   {text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travelAgent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
